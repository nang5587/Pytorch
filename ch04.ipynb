{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1479f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Malgun Gothic\"\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3f37de58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicDataset(Dataset):\n",
    "    def __init__(self, dataframe, target_column=None, transform=None, is_train=True):\n",
    "        self.dataframe = dataframe.copy() # 원본값 보존\n",
    "        self.target_column = target_column\n",
    "        self.transform = transform\n",
    "\n",
    "        self._preprocess()\n",
    "\n",
    "        # train dateset과 test dataset은 다르기 때문에 이런 과정이 필요\n",
    "        self.is_train = is_train\n",
    "        if self.is_train and target_column:\n",
    "            self.targets = self.dataframe[target_column].values # sklearn이랑 다르게 값만 넣어줘야 함\n",
    "            self.features = self.dataframe.drop([target_column], axis=1).values\n",
    "        else:\n",
    "            self.targets = None\n",
    "            self.features = self.dataframe.values\n",
    "\n",
    "    # _preprocess : \"_...\" => 밖에서 부르지마 ~\n",
    "    def _preprocess(self):\n",
    "        # 불필요한 컬럼 삭제\n",
    "        columns_to_drop = [\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"]\n",
    "        existing_columns = [\n",
    "            col for col in columns_to_drop if col in self.dataframe.columns\n",
    "        ]\n",
    "        if existing_columns:\n",
    "            self.dataframe.drop(existing_columns, axis=1, inplace=True)\n",
    "    \n",
    "        # 나이 결측값 처리 (중앙값)\n",
    "        if \"Age\" in self.dataframe.columns:\n",
    "            self.dataframe[\"Age\"].fillna(self.dataframe[\"Age\"].median(), inplace=True)\n",
    "\n",
    "        # 승선항구 결측값 (최빈값)\n",
    "        if \"Embarked\" in self.dataframe.columns:\n",
    "            self.dataframe[\"Embarked\"].fillna(\n",
    "                self.dataframe[\"Embarked\"].mode()[0], inplace=True\n",
    "            )\n",
    "\n",
    "        # 요금 (중앙값)\n",
    "        if \"Fare\" in self.dataframe.columns:\n",
    "            self.dataframe[\"Fare\"].fillna(self.dataframe[\"Fare\"].median(), inplace=True)\n",
    "\n",
    "        # 새로운 특성\n",
    "        if \"SibSp\" in self.dataframe.columns and \"Parch\" in self.dataframe.columns:\n",
    "            self.dataframe[\"FamilySize\"] = (\n",
    "                self.dataframe[\"SibSp\"] + self.dataframe[\"Parch\"] + 1\n",
    "            )\n",
    "            self.dataframe[\"IsAlone\"] = (self.dataframe[\"FamilySize\"] == 1).astype(int)\n",
    "\n",
    "        # 나이 그룹\n",
    "        if \"Age\" in self.dataframe.columns:\n",
    "            self.dataframe[\"AgeGroup\"] = pd.cut(\n",
    "                self.dataframe[\"Age\"],\n",
    "                bins=[0, 12, 18, 35, 60, 100],\n",
    "                labels=[0, 1, 2, 3, 4],\n",
    "            ).astype(int)\n",
    "\n",
    "        # 요금 그룹\n",
    "        if \"Fare\" in self.dataframe.columns:\n",
    "            self.dataframe[\"FareGroup\"] = pd.qcut(\n",
    "                self.dataframe[\"Fare\"], q=4, labels=[0, 1, 2, 3]\n",
    "            ).astype(int)\n",
    "\n",
    "        # 원-핫 인코딩\n",
    "        if \"Sex\" in self.dataframe.columns:\n",
    "            sex_dummies = pd.get_dummies(self.dataframe[\"Sex\"], drop_first=True)\n",
    "            self.dataframe = pd.concat([self.dataframe, sex_dummies], axis=1)\n",
    "            self.dataframe.drop([\"Sex\"], axis=1, inplace=True)\n",
    "\n",
    "        if \"Embarked\" in self.dataframe.columns:\n",
    "            embarked_dummies = pd.get_dummies(\n",
    "                self.dataframe[\"Embarked\"], drop_first=True\n",
    "            )\n",
    "            self.dataframe = pd.concat([self.dataframe, embarked_dummies], axis=1)\n",
    "            self.dataframe.drop([\"Embarked\"], axis=1, inplace=True)\n",
    "\n",
    "        # 나머지 결측 (평균)\n",
    "        self.dataframe.fillna(self.dataframe.mean(), inplace=True)\n",
    "        # print(f\"전처리 후 특성 수: {len(self.dataframe.columns)}\")\n",
    "        # print(f\"특성 목록: {list(self.dataframe.columns)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # [1,2,3,4,5]일 때\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        features = self.features[idx]\n",
    "        \n",
    "        # 변환 적용\n",
    "        if self.transform:\n",
    "            features = self.transform(features)\n",
    "            \n",
    "        features = torch.FloatTensor(features) # tensor로 바꿈\n",
    "\n",
    "        if self.is_train and self.targets is not None:\n",
    "            target = torch.LongTensor([self.targets[idx]])[0] # 스칼라\n",
    "            return features, target # train인 경우\n",
    "        else:\n",
    "            return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4ad95ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# tensor는 부울값을 자동으로 숫자로 안 만들어줘서 이 과정을 함\n",
    "class StandardScaleTransform:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, data):\n",
    "        self.scaler.fit(data)\n",
    "        self.fitted = True\n",
    "        return self\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        if not self.fitted: # 학습되었는지 확인\n",
    "            raise ValueError(\n",
    "                \"스케일러가 아직 학습되지 않았습니다. fit() 메서드를 먼저 호출하세요.\"\n",
    "            )\n",
    "\n",
    "        if sample.ndim == 1:\n",
    "            sample = sample.reshape(1, -1)\n",
    "            return self.scaler.transform(sample).flatten()\n",
    "        else:\n",
    "            return self.scaler.transform(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c28edb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "train_data = TitanicDataset(df_train, target_column=\"Survived\")\n",
    "test_data = TitanicDataset(df_test, is_train=False)\n",
    "\n",
    "transform = StandardScaleTransform()\n",
    "transform.fit(train_data.features)\n",
    "\n",
    "# 숫자로 바꾸는 처리\n",
    "train_data.transform = transform\n",
    "test_data.transform = transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "71057c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = random_split(train_data, [0.2, 0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "95222bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e2d80639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = train_data.features.shape[1]\n",
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e81786fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# super(TitanicNet, self).__init__()\n",
    "#         nn.Linear(input_size, 256) # 12 -> 256\n",
    "#         nn.BatchNorm1d(256) # 배치 정규화 : 레이어로 들어가는 입력값이 한쪽으로 쏠리거나 너무 퍼지거나 너무 좋아지지 않게 해주는 인공신경망 기법\n",
    "#         nn.ReLU() # 활성화\n",
    "#         nn.Dropout(0.5) # 임의의 것을 끊어냄 -> 신기하게 성능이 올라감... 근데 내려갈 때도 있다고 함..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "157763b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes=[256,128,64], dropout_rate=0.3):\n",
    "        super(TitanicNet, self).__init__()\n",
    "        layers=[]\n",
    "        prev_size = input_size\n",
    "\n",
    "        for i, hidden_size in enumerate(hidden_sizes):\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_size,hidden_size),\n",
    "                nn.BatchNorm1d(hidden_size),\n",
    "                nn.ReLU(), # 이것들이 한 계층\n",
    "                nn.Dropout(dropout_rate),\n",
    "            ])\n",
    "            prev_size = hidden_size\n",
    "\n",
    "        layers.append(nn.Linear(prev_size, 2))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e4674532",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = train_data.features.shape[1]\n",
    "model = TitanicNet(input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3d1e8399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TitanicNet(\n",
       "  (network): Sequential(\n",
       "    (0): Linear(in_features=12, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.3, inplace=False)\n",
       "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.3, inplace=False)\n",
       "    (12): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
